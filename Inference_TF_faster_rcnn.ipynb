{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "MUID = \"benching_1_hashtagTop_9_4238446d\""
      ],
      "metadata": {
        "id": "VUUxdlqSx0pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow-heif"
      ],
      "metadata": {
        "id": "dPjrASOiJEuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector"
      ],
      "metadata": {
        "id": "DeG2OsOXYnO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the TensorFlow Model Garden repository\n",
        "#!git clone https://github.com/tensorflow/models.git\n"
      ],
      "metadata": {
        "id": "FxZeGmvpZR5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get install protobuf-compiler python-lxml python-pil\n",
        "#!pip install Cython pandas tf-slim lvis"
      ],
      "metadata": {
        "id": "25rnhr_oZeZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cd into 'TensorFlow/models/research'\n",
        "#%cd '/content/models/research'\n",
        "#!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "4To7nCb3ZiPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#import sys\n",
        "#os.environ['PYTHONPATH']+=\":/content/models\"\n",
        "#sys.path.append(\"/content/models/research\")"
      ],
      "metadata": {
        "id": "2k2niP-xZqz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "0a5uhl6IZzka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python /content/models/research/object_detection/packages/tf2/setup.py build\n",
        "#!python /content/models/research/object_detection/packages/tf2/setup.py install"
      ],
      "metadata": {
        "id": "YEPX3FAaZ6Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##cd into 'TensorFlow/models/research/object_detection/builders/'\n",
        "#%cd '/content/models/research/object_detection/builders/'\n",
        "#!python model_builder_tf2_test.py\n",
        "#from object_detection.utils import label_map_util\n",
        "#from object_detection.utils import visualization_utils as viz_utils\n",
        "#print('Done')"
      ],
      "metadata": {
        "id": "pfwXtE2Ga1Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "a6_A6Q0ZcQD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget \"https://raw.githubusercontent.com/abundis-rmn2/graffiti_detection_OD_TF/main/labelmap.pbtxt\"\n",
        "#!wget \"https://data.abundis.com.mx/inference_graph.tar.gz\"\n",
        "!wget \"https://data.abundis.com.mx/config.json\"\n",
        "#!tar xvzf inference_graph.tar.gz\n",
        "!ls"
      ],
      "metadata": {
        "id": "ykI-CTeXbxKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5HlJ55vX4AO"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import argparse\n",
        "import mysql.connector\n",
        "import json\n",
        "\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import json\n",
        "\n",
        "from six import BytesIO\n",
        "from PIL import Image\n",
        "from pillow_heif import register_heif_opener\n",
        "\n",
        "register_heif_opener()\n",
        "Image.LOAD_TRUNCATED_IMAGES = True\n",
        "import ftplib\n",
        "\n",
        "# For running inference on the TF-Hub module.\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# For downloading the image.\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto the image.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring the inference time.\n",
        "import time\n",
        "import os\n",
        "# Print Tensorflow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  return img\n",
        "\n",
        "def run_inference_for_single_image(model, image):\n",
        "  converted_img  = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\n",
        "  print(\"inside inference converted_img\")\n",
        "  start_time = time.time()\n",
        "  output_dict = model(converted_img)\n",
        "  end_time = time.time()\n",
        "\n",
        "  #print(output_dict)\n",
        "  #result = {key:value.numpy() for key,value in output_dict.items()}\n",
        "  #print(result[\"detection_class_entities\"][:5]))\n",
        "  #print(result[\"detection_scores\"][:5]))\n",
        "  return output_dict\n",
        "\n",
        "def directory_exists(dir,ftp):\n",
        "    filelist = []\n",
        "    ftp.retrlines('LIST',filelist.append)\n",
        "    for f in filelist:\n",
        "        if f.split()[-1] == dir and f.upper().startswith('D'):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def DataUpload(local_dir, target_dir):\n",
        "    ftp_server.cwd('/media/exported_images_default')\n",
        "    if directory_exists(target_dir, ftp_server) is False:  # (or negate, whatever you prefer for readability)\n",
        "        print(target_dir)\n",
        "        ftp_server.mkd(target_dir)\n",
        "    ftp_server.cwd(target_dir)\n",
        "    # https://stackoverflow.com/questions/67520579/uploading-a-files-in-a-folder-to-ftp-using-python-ftplib\n",
        "    print(\"Uploading exported batch\")\n",
        "    toFTP = os.listdir(local_dir)\n",
        "    for filename in toFTP:\n",
        "        if filename not in ftp_server.nlst():\n",
        "            print(\"Uploading: \")\n",
        "            with open(os.path.join(local_dir, filename), 'rb') as file:  # Here I open the file using it's  full path\n",
        "                ftp_server.storbinary(f'STOR {filename}', file)  # Here I store the file in the FTP using only it's name as I intended\n",
        "            print(filename)\n",
        "        else:\n",
        "            print(\"File already exist\")\n",
        "    ftp_server.quit()\n",
        "\n",
        "def display_image(image):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)\n",
        "\n",
        "\n",
        "def download_and_resize_image(url, new_width=256, new_height=256,\n",
        "                              display=False):\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "  response = urlopen(url)\n",
        "  image_data = response.read()\n",
        "  image_data = BytesIO(image_data)\n",
        "  pil_image = Image.open(image_data)\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "  print(\"Image downloaded to %s.\" % filename)\n",
        "  if display:\n",
        "    display_image(pil_image)\n",
        "  return filename\n",
        "\n",
        "\n",
        "def draw_bounding_box_on_image(image,\n",
        "                               ymin,\n",
        "                               xmin,\n",
        "                               ymax,\n",
        "                               xmax,\n",
        "                               color,\n",
        "                               font,\n",
        "                               thickness=4,\n",
        "                               display_str_list=()):\n",
        "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
        "  print(\"inside draw_bounding_box_on_image\")\n",
        "  draw = ImageDraw.Draw(image)\n",
        "  im_width, im_height = image.size\n",
        "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
        "                                ymin * im_height, ymax * im_height)\n",
        "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
        "             (left, top)],\n",
        "            width=thickness,\n",
        "            fill=color)\n",
        "\n",
        "  # If the total height of the display strings added to the top of the bounding\n",
        "  # box exceeds the top of the image, stack the strings below the bounding box\n",
        "  # instead of above.\n",
        "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
        "  # Each display_str has a top and bottom margin of 0.05x.\n",
        "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
        "\n",
        "  if top > total_display_str_height:\n",
        "    text_bottom = top\n",
        "  else:\n",
        "    text_bottom = top + total_display_str_height\n",
        "  # Reverse list and print from bottom to top.\n",
        "\n",
        "\n",
        "  for display_str in display_str_list[::-1]:\n",
        "    text_width, text_height = font.getsize(display_str)\n",
        "    margin = np.ceil(0.05 * text_height)\n",
        "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
        "                    (left + text_width, text_bottom)],\n",
        "                   fill=color)\n",
        "    draw.text((left + margin, text_bottom - text_height - margin),\n",
        "              display_str,\n",
        "              fill=\"black\",\n",
        "              font=font)\n",
        "    text_bottom -= text_height - 2 * margin\n",
        "\n",
        "\n",
        "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.5):\n",
        "  print(\"inside draw_boxes\")\n",
        "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
        "  colors = list(ImageColor.colormap.values())\n",
        "  try:\n",
        "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
        "                              25)\n",
        "  except IOError:\n",
        "    print(\"Font not found, using default font.\")\n",
        "    font = ImageFont.load_default()\n",
        "  print(\"inside draw_boxes 2\")\n",
        "  for i in range(min(boxes.shape[0], max_boxes)):\n",
        "    print(\"inside draw_boxes loop\")\n",
        "    if scores[i] >= min_score:\n",
        "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
        "\n",
        "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
        "                                     int(100 * scores[i]))\n",
        "      color = colors[hash(class_names[i]) % len(colors)]\n",
        "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
        "      print(\"inside draw_boxes after image_pil\")\n",
        "      draw_bounding_box_on_image(\n",
        "          image_pil,\n",
        "          ymin,\n",
        "          xmin,\n",
        "          ymax,\n",
        "          xmax,\n",
        "          color,\n",
        "          font,\n",
        "          display_str_list=[display_str])\n",
        "      np.copyto(image, np.array(image_pil))\n",
        "  print(\"return draw_boxes\")\n",
        "  return image"
      ],
      "metadata": {
        "id": "FNF_5vcobO8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Load tf model\")\n",
        "\n",
        "global_time = time.time()\n",
        "\n",
        "c = open(\"config.json\")\n",
        "config = json.load(c)\n",
        "\n",
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
        "\n",
        "model = hub.load(module_handle).signatures['default']"
      ],
      "metadata": {
        "id": "N0kpqotObZNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_exist = os.path.exists(\"./exported_images/\" + MUID)\n",
        "if not dir_exist:\n",
        "    #os.makedirs(user_dir, 0o777)\n",
        "    os.makedirs(\"./exported_images/\" + MUID, 0o777)\n",
        "    print(\"The dir was created\")\n",
        "else:\n",
        "    print(\"The dir already exist\")\n",
        "\n",
        "dir_exist = os.path.exists(\"./downloaded_images/\")\n",
        "if not dir_exist:\n",
        "    #os.makedirs(user_dir, 0o777)\n",
        "    os.makedirs(\"./downloaded_images/\", 0o777)\n",
        "    print(\"The dir was created\")\n",
        "else:\n",
        "    print(\"The dir already exist\")\n",
        "\n",
        "try:\n",
        "    cnx = mysql.connector.connect(user=config[\"SQL\"][\"username\"],\n",
        "                                  password=config[\"SQL\"][\"password\"],\n",
        "                                  host=config[\"SQL\"][\"hostname\"],\n",
        "                                  database=config[\"SQL\"][\"database\"],\n",
        "                                  )\n",
        "except mysql.connector.Error as err:\n",
        "    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
        "        print(\"Something is wrong with your user name or password\")\n",
        "    elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
        "        print(\"Database does not exist\")\n",
        "    else:\n",
        "        print(err)\n",
        "else:\n",
        "    print(\"Looking for caption in MUID:\", MUID)\n",
        "    cursor = cnx.cursor()\n",
        "    cursor.execute(\"SELECT * FROM data_media WHERE MUID IN ('%s') \" % (MUID))\n",
        "    posts = cursor.fetchall()\n",
        "    print(\"MUID found :\", len(posts))\n",
        "    asset_url = ''\n",
        "    img_format = ''\n",
        "\n",
        "    for post in posts:\n",
        "        inference_dict = []\n",
        "        #print(\"Image post\")\n",
        "        print(post)\n",
        "        print(post[6])\n",
        "\n",
        "        #for works started\n",
        "        #if post[6] == 1 and post[15] == None:\n",
        "        #for barredora\n",
        "        if post[6] == 1:\n",
        "          print(\"Image post\")\n",
        "          print(post)\n",
        "          asset_url_jpg = \"https://data.abundis.com.mx/media/\" + post[14] + \"/\" + post[1] + \"_\" + post[3] + \".jpg\"\n",
        "          asset_url_webp = \"https://data.abundis.com.mx/media/\" + post[14] + \"/\" + post[1] + \"_\" + post[3] + \".webp\"\n",
        "          asset_url_heic = \"https://data.abundis.com.mx/media/\" + post[14] + \"/\" + post[1] + \"_\" + post[3] + \".heic\"\n",
        "          print(asset_url_jpg)\n",
        "          print(asset_url_webp)\n",
        "          print(asset_url_heic)\n",
        "          r_jpg = requests.head(asset_url_jpg)\n",
        "          r_webp = requests.head(asset_url_webp)\n",
        "          r_heic = requests.head(asset_url_heic)\n",
        "          print(r_jpg)\n",
        "          print(r_webp)\n",
        "          print(r_heic)\n",
        "          if r_webp.headers['Content-Type'] == 'image/webp':\n",
        "            print(\"WEBP \",asset_url_webp)\n",
        "            asset_url = asset_url_webp\n",
        "            img_format= \"webp\"\n",
        "          elif r_jpg.headers['Content-Type'] == 'image/jpeg':\n",
        "            print(\"JPG \",asset_url_jpg)\n",
        "            asset_url = asset_url_jpg\n",
        "            img_format = \"jpg\"\n",
        "          #elif r_heic.headers['Content-Type'] == 'image/heic':\n",
        "          #elif r_heic==\"<Response [200]>\" and r_jpg==\"<Response [404]>\" and r_webp==\"<Response [404]>\":\n",
        "          elif r_heic.status_code == 200:\n",
        "            print(\"HEIC \",asset_url_heic)\n",
        "            asset_url = asset_url_heic\n",
        "            img_format = \"heic\"\n",
        "\n",
        "          print(\"Image URL\")\n",
        "          print(asset_url)\n",
        "\n",
        "          img_data = requests.get(asset_url).content\n",
        "          if img_format == 'webp':\n",
        "              with open('./downloaded_images/'+post[4]+'.webp', 'wb') as handler:\n",
        "                  handler.write(img_data)\n",
        "              filename = post[4]+'_exported.webp'\n",
        "              try:\n",
        "                image_np = load_image_into_numpy_array('./downloaded_images/' + post[4] + '.webp')\n",
        "                print(\"inference\")\n",
        "                output_dict = run_inference_for_single_image(model, image_np)\n",
        "                result = {key:value.numpy() for key,value in output_dict.items()}\n",
        "\n",
        "                print(\"File inferences\", filename)\n",
        "                print(\"with at least 0.5 of score\")\n",
        "                #print(output_dict)\n",
        "\n",
        "                for d_class, d_score in zip(output_dict['detection_class_entities'], output_dict['detection_scores']):\n",
        "                    if d_score > 0.5:\n",
        "                      d_class = str(d_class.numpy())\n",
        "                      d_class = d_class[2:-1]\n",
        "                      print('{0} with score {1}'.format(d_class, float(d_score)))\n",
        "                      print(type(d_class))\n",
        "                      inference_dict.append( (d_class, float(d_score)) )\n",
        "\n",
        "                print(\"hay imagen?\")\n",
        "\n",
        "                image_with_boxes = draw_boxes(\n",
        "                    image_np.numpy(), result[\"detection_boxes\"],\n",
        "                    result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
        "                print(\"hay imagen?\")\n",
        "                #display_image(image_with_boxes)\n",
        "                im = Image.fromarray(image_with_boxes)\n",
        "                im.save('./exported_images/' +MUID+ '/' + filename)\n",
        "\n",
        "              except:\n",
        "                pass\n",
        "\n",
        "\n",
        "\n",
        "          elif img_format == 'jpg':\n",
        "              with open('./downloaded_images/'+post[4]+'.jpg', 'wb') as handler:\n",
        "                  handler.write(img_data)\n",
        "              filename = post[4] + '_exported.jpg'\n",
        "              try:\n",
        "                image_np = load_image_into_numpy_array('./downloaded_images/' + post[4] + '.jpg')\n",
        "                print(\"inference\")\n",
        "                output_dict = run_inference_for_single_image(model, image_np)\n",
        "                result = {key:value.numpy() for key,value in output_dict.items()}\n",
        "\n",
        "                print(\"File inferences\", filename)\n",
        "                print(\"with at least 0.5 of score\")\n",
        "                #print(output_dict)\n",
        "\n",
        "                for d_class, d_score in zip(output_dict['detection_class_entities'], output_dict['detection_scores']):\n",
        "                    if d_score > 0.5:\n",
        "                      d_class = str(d_class.numpy())\n",
        "                      d_class = d_class[2:-1]\n",
        "                      print('{0} with score {1}'.format(d_class, float(d_score)))\n",
        "                      print(type(d_class))\n",
        "                      inference_dict.append( (d_class, float(d_score)) )\n",
        "\n",
        "                print(\"hay imagen?\")\n",
        "\n",
        "                image_with_boxes = draw_boxes(\n",
        "                    image_np.numpy(), result[\"detection_boxes\"],\n",
        "                    result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
        "                print(\"hay imagen?\")\n",
        "                #display_image(image_with_boxes)\n",
        "                im = Image.fromarray(image_with_boxes)\n",
        "                im.save('./exported_images/' +MUID+ '/' + filename)\n",
        "\n",
        "              except:\n",
        "                pass\n",
        "\n",
        "          elif img_format == 'heic':\n",
        "              with open('./downloaded_images/'+post[4]+'.heic', 'wb') as handler:\n",
        "                  handler.write(img_data)\n",
        "              filename = post[4] + '_exported.jpg'\n",
        "              try:\n",
        "                image_np = load_image_into_numpy_array('./downloaded_images/' + post[4] + '.heic')\n",
        "                print(\"inference\")\n",
        "                output_dict = run_inference_for_single_image(model, image_np)\n",
        "                result = {key:value.numpy() for key,value in output_dict.items()}\n",
        "\n",
        "                print(\"File inferences\", filename)\n",
        "                print(\"with at least 0.5 of score\")\n",
        "                #print(output_dict)\n",
        "\n",
        "                for d_class, d_score in zip(output_dict['detection_class_entities'], output_dict['detection_scores']):\n",
        "                    if d_score > 0.5:\n",
        "                      d_class = str(d_class.numpy())\n",
        "                      d_class = d_class[2:-1]\n",
        "                      print('{0} with score {1}'.format(d_class, float(d_score)))\n",
        "                      print(type(d_class))\n",
        "                      inference_dict.append( (d_class, float(d_score)) )\n",
        "\n",
        "                print(\"hay imagen?\")\n",
        "\n",
        "                image_with_boxes = draw_boxes(\n",
        "                    image_np.numpy(), result[\"detection_boxes\"],\n",
        "                    result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
        "                print(\"hay imagen?\")\n",
        "                #display_image(image_with_boxes)\n",
        "                im = Image.fromarray(image_with_boxes)\n",
        "                im.save('./exported_images/' +MUID+ '/' + filename)\n",
        "\n",
        "              except:\n",
        "                pass\n",
        "\n",
        "          print(\"Inference to JSON and then SQL\")\n",
        "          inference_json = json.dumps(inference_dict)\n",
        "          print(inference_json)\n",
        "          cnx.reconnect()\n",
        "          innercursor = cnx.cursor()\n",
        "          sql_inference = \"UPDATE data_media SET inference_world = %s WHERE id = %s\"\n",
        "          val = (inference_json, post[0])\n",
        "          innercursor.execute(sql_inference, val)\n",
        "          cnx.commit()\n",
        "\n",
        "    print(innercursor.rowcount, \"registros afectado/s\")"
      ],
      "metadata": {
        "id": "SFu8UGA7bbbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QSHTxOqJHJCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = open(\"config.json\")\n",
        "config = json.load(c)\n",
        "ftp_server = ftplib.FTP(config[\"FTP\"][\"hostname\"],config[\"FTP\"][\"username\"],config[\"FTP\"][\"password\"])\n",
        "ftp_server.encoding = \"utf-8\"\n",
        "#ftp_server.login()"
      ],
      "metadata": {
        "id": "buPWo3zanodO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataUpload('./exported_images/' +MUID+ '/', MUID)\n",
        "ftp_server.close()"
      ],
      "metadata": {
        "id": "ydZYpXDu9go7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/portlandbench_1_hashtagTop_9_a93fe60f.zip /content/exported_images/portlandbench_1_hashtagTop_9_a93fe60f\n",
        "#from google.colab import files\n",
        "#files.download(\"/content/portlandbench_1_hashtagTop_9_a93fe60f.zip\")"
      ],
      "metadata": {
        "id": "Xqd3R_efKSlB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}